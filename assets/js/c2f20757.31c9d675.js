"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[816],{3905:(e,t,a)=>{a.d(t,{Zo:()=>m,kt:()=>h});var r=a(7294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},i=Object.keys(e);for(r=0;r<i.length;r++)a=i[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)a=i[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var s=r.createContext({}),p=function(e){var t=r.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},m=function(e){var t=p(e.components);return r.createElement(s.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},u=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,i=e.originalType,s=e.parentName,m=l(e,["components","mdxType","originalType","parentName"]),u=p(a),h=n,d=u["".concat(s,".").concat(h)]||u[h]||c[h]||i;return a?r.createElement(d,o(o({ref:t},m),{},{components:a})):r.createElement(d,o({ref:t},m))}));function h(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=a.length,o=new Array(i);o[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:n,o[1]=l;for(var p=2;p<i;p++)o[p]=a[p];return r.createElement.apply(null,o)}return r.createElement.apply(null,a)}u.displayName="MDXCreateElement"},6185:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>c,frontMatter:()=>i,metadata:()=>l,toc:()=>p});var r=a(7462),n=(a(7294),a(3905));const i={},o=void 0,l={unversionedId:"Books/EffectiveJava3/Chapter-7/Chapter-7-Item-48-Use-caution-when-making-streams-parallel",id:"Books/EffectiveJava3/Chapter-7/Chapter-7-Item-48-Use-caution-when-making-streams-parallel",title:"Chapter-7-Item-48-Use-caution-when-making-streams-parallel",description:"Chapter 7. Lambdas and Streams\uff08\u03bb \u8868\u8fbe\u5f0f\u548c\u6d41\uff09",source:"@site/docs/Books/EffectiveJava3/Chapter-7/Chapter-7-Item-48-Use-caution-when-making-streams-parallel.md",sourceDirName:"Books/EffectiveJava3/Chapter-7",slug:"/Books/EffectiveJava3/Chapter-7/Chapter-7-Item-48-Use-caution-when-making-streams-parallel",permalink:"/docs/Books/EffectiveJava3/Chapter-7/Chapter-7-Item-48-Use-caution-when-making-streams-parallel",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Books/EffectiveJava3/Chapter-7/Chapter-7-Item-48-Use-caution-when-making-streams-parallel.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Chapter-7-Item-47-Prefer-Collection-to-Stream-as-a-return-type",permalink:"/docs/Books/EffectiveJava3/Chapter-7/Chapter-7-Item-47-Prefer-Collection-to-Stream-as-a-return-type"},next:{title:"Chapter-8-Introduction",permalink:"/docs/Books/EffectiveJava3/Chapter-8/Chapter-8-Introduction"}},s={},p=[{value:"Chapter 7. Lambdas and Streams\uff08\u03bb \u8868\u8fbe\u5f0f\u548c\u6d41\uff09",id:"chapter-7-lambdas-and-streams\u03bb-\u8868\u8fbe\u5f0f\u548c\u6d41",level:2},{value:"Item 48: Use caution when making streams parallel\uff08\u8c28\u614e\u4f7f\u7528\u5e76\u884c\u6d41\uff09",id:"item-48-use-caution-when-making-streams-parallel\u8c28\u614e\u4f7f\u7528\u5e76\u884c\u6d41",level:3}],m={toc:p};function c(e){let{components:t,...a}=e;return(0,n.kt)("wrapper",(0,r.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h2",{id:"chapter-7-lambdas-and-streams\u03bb-\u8868\u8fbe\u5f0f\u548c\u6d41"},"Chapter 7. Lambdas and Streams\uff08\u03bb \u8868\u8fbe\u5f0f\u548c\u6d41\uff09"),(0,n.kt)("h3",{id:"item-48-use-caution-when-making-streams-parallel\u8c28\u614e\u4f7f\u7528\u5e76\u884c\u6d41"},"Item 48: Use caution when making streams parallel\uff08\u8c28\u614e\u4f7f\u7528\u5e76\u884c\u6d41\uff09"),(0,n.kt)("p",null,"Among mainstream languages, Java has always been at the forefront of providing facilities to ease the task of concurrent programming. When Java was released in 1996, it had built-in support for threads, with synchronization and wait/notify. Java 5 introduced the java.util.concurrent library, with concurrent collections and the executor framework. Java 7 introduced the fork-join package, a high-performance framework for parallel decomposition. Java 8 introduced streams, which can be parallelized with a single call to the parallel method. Writing concurrent programs in Java keeps getting easier, but writing concurrent programs that are correct and fast is as difficult as it ever was. Safety and liveness violations are a fact of life in concurrent programming, and parallel stream pipelines are no exception."),(0,n.kt)("p",null,"\u5728\u4e3b\u6d41\u8bed\u8a00\u4e2d\uff0cJava \u4e00\u76f4\u8d70\u5728\u63d0\u4f9b\u7b80\u5316\u5e76\u53d1\u7f16\u7a0b\u4efb\u52a1\u5de5\u5177\u7684\u524d\u5217\u3002\u5f53 Java \u5728 1996 \u5e74\u53d1\u5e03\u65f6\uff0c\u5b83\u5185\u7f6e\u4e86\u5bf9\u7ebf\u7a0b\u7684\u652f\u6301\uff0c\u652f\u6301\u540c\u6b65\u548c wait/notify\u3002Java 5 \u5f15\u5165\u4e86 ",(0,n.kt)("inlineCode",{parentName:"p"},"java.util.concurrent"),"\u3002\u5177\u6709\u5e76\u53d1\u96c6\u5408\u548c\u6267\u884c\u5668\u6846\u67b6\u7684\u5e76\u53d1\u5e93\u3002Java 7 \u5f15\u5165\u4e86 fork-join \u5305\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u5e76\u884c\u5206\u89e3\u7684\u9ad8\u6027\u80fd\u6846\u67b6\u3002Java 8 \u5f15\u5165\u4e86\u6d41\uff0c\u5b83\u53ef\u4ee5\u901a\u8fc7\u5bf9 parallel \u65b9\u6cd5\u7684\u4e00\u6b21\u8c03\u7528\u6765\u5e76\u884c\u5316\u3002\u7528 Java \u7f16\u5199\u5e76\u53d1\u7a0b\u5e8f\u53d8\u5f97\u8d8a\u6765\u8d8a\u5bb9\u6613\uff0c\u4f46\u662f\u7f16\u5199\u6b63\u786e\u4e14\u5feb\u901f\u7684\u5e76\u53d1\u7a0b\u5e8f\u5374\u548c\u4ee5\u524d\u4e00\u6837\u56f0\u96be\u3002\u5728\u5e76\u53d1\u7f16\u7a0b\u4e2d\uff0c\u5b89\u5168\u6027\u548c\u6d3b\u6027\u7684\u8fdd\u53cd\u662f\u4e0d\u53ef\u907f\u514d\u7684\uff0c\u5e76\u884c\u6d41\u7ba1\u9053\u4e5f\u4e0d\u4f8b\u5916\u3002"),(0,n.kt)("p",null,"Consider this program from Item 45:"),(0,n.kt)("p",null,"\u8003\u8651 ",(0,n.kt)("a",{parentName:"p",href:"./Chapter-7-Item-45-Use-streams-judiciously"},"Item-45")," \u7684\u7a0b\u5e8f\uff1a"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"// Stream-based program to generate the first 20 Mersenne primes\npublic static void main(String[] args) {\n    primes().map(p -> TWO.pow(p.intValueExact()).subtract(ONE))\n    .filter(mersenne -> mersenne.isProbablePrime(50))\n    .limit(20)\n    .forEach(System.out::println);\n}\n\nstatic Stream<BigInteger> primes() {\n    return Stream.iterate(TWO, BigInteger::nextProbablePrime);\n}\n")),(0,n.kt)("p",null,"On my machine, this program immediately starts printing primes and takes 12.5 seconds to run to completion. Suppose I naively try to speed it up by adding a call to parallel() to the stream pipeline. What do you think will happen to its performance? Will it get a few percent faster? A few percent slower? Sadly, what happens is that it doesn\u2019t print anything, but CPU usage spikes to 90 percent and stays there indefinitely (a liveness failure). The program might terminate eventually, but I was unwilling to find out; I stopped it forcibly after half an hour."),(0,n.kt)("p",null,"\u5728\u6211\u7684\u673a\u5668\u4e0a\uff0c\u8fd9\u4e2a\u7a0b\u5e8f\u7acb\u5373\u5f00\u59cb\u6253\u5370\u7d20\u6570\uff0c\u8fd0\u884c 12.5 \u79d2\u5b8c\u6210\u3002\u5047\u8bbe\u6211\u5929\u771f\u5730\u5c1d\u8bd5\u901a\u8fc7\u5411\u6d41\u7ba1\u9053\u6dfb\u52a0\u5bf9 ",(0,n.kt)("inlineCode",{parentName:"p"},"parallel()")," \u7684\u8c03\u7528\u6765\u52a0\u901f\u5b83\u3002\u4f60\u8ba4\u4e3a\u5b83\u7684\u6027\u80fd\u4f1a\u600e\u4e48\u6837\uff1f\u5b83\u4f1a\u5feb\u51e0\u4e2a\u767e\u5206\u70b9\u5417\uff1f\u6162\u4e86\u51e0\u4e2a\u767e\u5206\u70b9\uff1f\u9057\u61be\u7684\u662f\uff0c\u5b83\u4e0d\u4f1a\u6253\u5370\u4efb\u4f55\u4e1c\u897f\uff0c\u4f46\u662f CPU \u4f7f\u7528\u7387\u4f1a\u98d9\u5347\u5230 90%\uff0c\u5e76\u4e14\u4f1a\u65e0\u9650\u671f\u5730\u505c\u7559\u5728\u90a3\u91cc\uff08\u6d3b\u8dc3\u6027\u5931\u8d25\uff09\u3002\u8fd9\u4e2a\u9879\u76ee\u6700\u7ec8\u53ef\u80fd\u4f1a\u7ec8\u6b62\uff0c\u4f46\u6211\u4e0d\u613f\u610f\u77e5\u9053\uff1b\u534a\u5c0f\u65f6\u540e\u6211\u5f3a\u884c\u505c\u4e86\u4e0b\u6765\u3002"),(0,n.kt)("p",null,"What\u2019s going on here? Simply put, the streams library has no idea how to parallelize this pipeline and the heuristics fail. Even under the best of circumstances, ",(0,n.kt)("strong",{parentName:"p"},"parallelizing a pipeline is unlikely to increase its performance if the source is from Stream.iterate, or the intermediate operation limit is used.")," This pipeline has to contend with both of these issues. Worse, the default parallelization strategy deals with the unpredictability of limit by assuming there\u2019s no harm in processing a few extra elements and discarding any unneeded results. In this case, it takes roughly twice as long to find each Mersenne prime as it did to find the previous one. Thus, the cost of computing a single extra element is roughly equal to the cost of computing all previous elements combined, and this innocuous-looking pipeline brings the automatic parallelization algorithm to its knees. The moral of this story is simple: ",(0,n.kt)("strong",{parentName:"p"},"Do not parallelize stream pipelines indiscriminately.")," The performance consequences may be disastrous."),(0,n.kt)("p",null,"\u8fd9\u662f\u600e\u4e48\u56de\u4e8b\uff1f\u7b80\u5355\u5730\u8bf4\uff0cstream \u5e93\u4e0d\u77e5\u9053\u5982\u4f55\u5e76\u884c\u5316\u8fd9\u4e2a\u7ba1\u9053\uff0c\u56e0\u6b64\u542f\u53d1\u5f0f\u4f1a\u5931\u8d25\u3002\u5373\u4f7f\u5728\u6700\u597d\u7684\u60c5\u51b5\u4e0b\uff0c",(0,n.kt)("strong",{parentName:"p"},"\u5982\u679c\u6e90\u6765\u81ea ",(0,n.kt)("inlineCode",{parentName:"strong"},"Stream.iterate")," \u6216\u4f7f\u7528 Intermediate \u64cd\u4f5c\u9650\u5236\uff0c\u5e76\u884c\u5316\u7ba1\u9053\u4e5f\u4e0d\u592a\u53ef\u80fd\u63d0\u9ad8\u5176\u6027\u80fd\u3002")," \u8fd9\u6761\u7ba1\u9053\u5fc5\u987b\u89e3\u51b3\u8fd9\u4e24\u4e2a\u95ee\u9898\u3002\u66f4\u7cdf\u7cd5\u7684\u662f\uff0c\u9ed8\u8ba4\u7684\u5e76\u884c\u5316\u7b56\u7565\u901a\u8fc7\u5047\u8bbe\u5904\u7406\u4e00\u4e9b\u989d\u5916\u7684\u5143\u7d20\u548c\u4e22\u5f03\u4efb\u4f55\u4e0d\u9700\u8981\u7684\u7ed3\u679c\u6ca1\u6709\u5bb3\u5904\u6765\u5904\u7406\u6781\u9650\u7684\u4e0d\u53ef\u9884\u6d4b\u6027\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u627e\u5230\u6bcf\u4e00\u4e2a Mersenne \u7d20\u6570\u6240\u9700\u7684\u65f6\u95f4\u5927\u7ea6\u662f\u627e\u5230\u4e0a\u4e00\u4e2a Mersenne \u7d20\u6570\u6240\u9700\u65f6\u95f4\u7684\u4e24\u500d\u3002\u56e0\u6b64\uff0c\u8ba1\u7b97\u5355\u4e2a\u989d\u5916\u5143\u7d20\u7684\u6210\u672c\u5927\u81f4\u7b49\u4e8e\u8ba1\u7b97\u4e4b\u524d\u6240\u6709\u5143\u7d20\u7684\u603b\u548c\uff0c\u800c\u8fd9\u6761\u770b\u4e0a\u53bb\u6beb\u65e0\u95ee\u9898\u7684\u7ba1\u9053\u5c06\u81ea\u52a8\u5e76\u884c\u5316\u7b97\u6cd5\u63a8\u5230\u4e86\u6781\u81f4\u3002\u8fd9\u4e2a\u6545\u4e8b\u7684\u5bd3\u610f\u5f88\u7b80\u5355\uff1a",(0,n.kt)("strong",{parentName:"p"},"\u4e0d\u8981\u4e0d\u52a0\u533a\u522b\u5730\u5c06\u6d41\u7ba1\u9053\u5e76\u884c\u5316\u3002")," \u6027\u80fd\u540e\u679c\u53ef\u80fd\u662f\u707e\u96be\u6027\u7684\u3002"),(0,n.kt)("p",null,"As a rule, ",(0,n.kt)("strong",{parentName:"p"},"performance gains from parallelism are best on streams over ArrayList, HashMap, HashSet, and ConcurrentHashMap instances; arrays; int ranges; and long ranges.")," What these data structures have in common is that they can all be accurately and cheaply split into subranges of any desired sizes, which makes it easy to divide work among parallel threads. The abstraction used by the streams library to perform this task is the spliterator, which is returned by the spliterator method on Stream and Iterable."),(0,n.kt)("p",null,"\u901a\u5e38\uff0c",(0,n.kt)("strong",{parentName:"p"},"\u5e76\u884c\u6027\u5e26\u6765\u7684\u6027\u80fd\u63d0\u5347\u5728 ArrayList\u3001HashMap\u3001HashSet \u548c ConcurrentHashMap \u5b9e\u4f8b\u4e0a\u7684\u6d41\u6548\u679c\u6700\u597d\uff1bint \u6570\u7ec4\u548c long \u6570\u7ec4\u4e5f\u5728\u5176\u4e2d\u3002")," \u8fd9\u4e9b\u6570\u636e\u7ed3\u6784\u7684\u5171\u540c\u4e4b\u5904\u5728\u4e8e\uff0c\u5b83\u4eec\u90fd\u53ef\u4ee5\u88ab\u7cbe\u786e\u4e14\u5ec9\u4ef7\u5730\u5206\u5272\u6210\u4efb\u610f\u5927\u5c0f\u7684\u5b50\u7a0b\u5e8f\uff0c\u8fd9\u4f7f\u5f97\u5728\u5e76\u884c\u7ebf\u7a0b\u4e4b\u95f4\u5212\u5206\u5de5\u4f5c\u53d8\u5f97\u5f88\u5bb9\u6613\u3002stream \u5e93\u7528\u4e8e\u6267\u884c\u6b64\u4efb\u52a1\u7684\u62bd\u8c61\u662f spliterator\uff0c\u5b83\u7531\u6d41\u4e0a\u7684 spliterator \u65b9\u6cd5\u8fd4\u56de\u5e76\u53ef\u8fed\u4ee3\u3002"),(0,n.kt)("p",null,"Another important factor that all of these data structures have in common is that they provide good-to-excellent locality of reference when processed sequentially: sequential element references are stored together in memory. The objects referred to by those references may not be close to one another in memory, which reduces locality-of-reference. Locality-of-reference turns out to be critically important for parallelizing bulk operations: without it, threads spend much of their time idle, waiting for data to be transferred from memory into the processor\u2019s cache. The data structures with the best locality of reference are primitive arrays because the data itself is stored contiguously in memory."),(0,n.kt)("p",null,"\u6240\u6709\u8fd9\u4e9b\u6570\u636e\u7ed3\u6784\u7684\u53e6\u4e00\u4e2a\u91cd\u8981\u5171\u540c\u70b9\u662f\uff0c\u5f53\u6309\u987a\u5e8f\u5904\u7406\u65f6\uff0c\u5b83\u4eec\u63d0\u4f9b\u4e86\u4ece\u4f18\u79c0\u5230\u4f18\u79c0\u7684\u5f15\u7528\u4f4d\u7f6e\uff1a\u987a\u5e8f\u5143\u7d20\u5f15\u7528\u4e00\u8d77\u5b58\u50a8\u5728\u5185\u5b58\u4e2d\u3002\u8fd9\u4e9b\u5f15\u7528\u5f15\u7528\u7684\u5bf9\u8c61\u5728\u5185\u5b58\u4e2d\u53ef\u80fd\u5f7c\u6b64\u4e0d\u592a\u63a5\u8fd1\uff0c\u8fd9\u964d\u4f4e\u4e86\u5f15\u7528\u7684\u4f4d\u7f6e\u3002\u5f15\u7528\u4f4d\u7f6e\u5bf9\u4e8e\u5e76\u884c\u5316\u6279\u91cf\u64cd\u4f5c\u975e\u5e38\u91cd\u8981\uff1a\u5982\u679c\u6ca1\u6709\u5b83\uff0c\u7ebf\u7a0b\u5c06\u82b1\u8d39\u5927\u91cf\u65f6\u95f4\u7a7a\u95f2\uff0c\u7b49\u5f85\u6570\u636e\u4ece\u5185\u5b58\u4f20\u8f93\u5230\u5904\u7406\u5668\u7684\u7f13\u5b58\u4e2d\u3002\u5177\u6709\u6700\u4f73\u5f15\u7528\u4f4d\u7f6e\u7684\u6570\u636e\u7ed3\u6784\u662f\u57fa\u672c\u6570\u7ec4\uff0c\u56e0\u4e3a\u6570\u636e\u672c\u8eab\u662f\u8fde\u7eed\u5b58\u50a8\u5728\u5185\u5b58\u4e2d\u7684\u3002"),(0,n.kt)("p",null,"The nature of a stream pipeline\u2019s terminal operation also affects the effectiveness of parallel execution. If a significant amount of work is done in the terminal operation compared to the overall work of the pipeline and that operation is inherently sequential, then parallelizing the pipeline will have limited effectiveness. The best terminal operations for parallelism are reductions, where all of the elements emerging from the pipeline are combined using one of Stream\u2019s reduce methods, or prepackaged reductions such as min, max, count, and sum. The short-circuiting operations anyMatch, allMatch, and noneMatch are also amenable to parallelism. The operations performed by Stream\u2019s collect method, which are known as mutable reductions, are not good candidates for parallelism because the overhead of combining collections is costly."),(0,n.kt)("p",null,"\u6d41\u7ba1\u9053 Terminal \u64cd\u4f5c\u7684\u6027\u8d28\u4e5f\u4f1a\u5f71\u54cd\u5e76\u884c\u6267\u884c\u7684\u6709\u6548\u6027\u3002\u5982\u679c\u4e0e\u7ba1\u9053\u7684\u603b\u4f53\u5de5\u4f5c\u76f8\u6bd4\uff0c\u5728 Terminal \u64cd\u4f5c\u4e2d\u5b8c\u6210\u4e86\u5927\u91cf\u7684\u5de5\u4f5c\uff0c\u5e76\u4e14\u8be5\u64cd\u4f5c\u672c\u8d28\u4e0a\u662f\u987a\u5e8f\u7684\uff0c\u90a3\u4e48\u7ba1\u9053\u7684\u5e76\u884c\u5316\u5c06\u5177\u6709\u6709\u9650\u7684\u6709\u6548\u6027\u3002\u5e76\u884c\u6027\u7684\u6700\u4f73 Terminal \u64cd\u4f5c\u662f\u7f29\u51cf\uff0c\u5176\u4e2d\u6765\u81ea\u7ba1\u9053\u7684\u6240\u6709\u5143\u7d20\u90fd\u4f7f\u7528\u6d41\u7684\u7f29\u51cf\u65b9\u6cd5\u4e4b\u4e00\u8fdb\u884c\u7ec4\u5408\uff0c\u6216\u8005\u4f7f\u7528\u9884\u5148\u6253\u5305\u7684\u7f29\u51cf\uff0c\u5982\u6700\u5c0f\u3001\u6700\u5927\u3001\u8ba1\u6570\u548c\u548c\u3002anyMatch\u3001allMatch \u548c noneMatch \u7684\u77ed\u8def\u64cd\u4f5c\u4e5f\u9002\u7528\u4e8e\u5e76\u884c\u6027\u3002\u6d41\u7684 collect \u65b9\u6cd5\u6267\u884c\u7684\u64cd\u4f5c\u79f0\u4e3a\u53ef\u53d8\u7f29\u51cf\uff0c\u5b83\u4eec\u4e0d\u662f\u5e76\u884c\u6027\u7684\u597d\u5019\u9009\uff0c\u56e0\u4e3a\u7ec4\u5408\u96c6\u5408\u7684\u5f00\u9500\u662f\u6602\u8d35\u7684\u3002"),(0,n.kt)("p",null,"If you write your own Stream, Iterable, or Collection implementation and you want decent parallel performance, you must override the spliterator method and test the parallel performance of the resulting streams extensively. Writing high-quality spliterators is difficult and beyond the scope of this book."),(0,n.kt)("p",null,"\u5982\u679c\u4f60\u7f16\u5199\u81ea\u5df1\u7684\u6d41\u3001Iterable \u6216 Collection \u5b9e\u73b0\uff0c\u5e76\u4e14\u5e0c\u671b\u83b7\u5f97\u826f\u597d\u7684\u5e76\u884c\u6027\u80fd\uff0c\u5219\u5fc5\u987b\u91cd\u5199 spliterator \u65b9\u6cd5\uff0c\u5e76\u5e7f\u6cdb\u5730\u6d4b\u8bd5\u7ed3\u679c\u6d41\u7684\u5e76\u884c\u6027\u80fd\u3002\u7f16\u5199\u9ad8\u8d28\u91cf\u7684 spliterator \u662f\u56f0\u96be\u7684\uff0c\u8d85\u51fa\u4e86\u672c\u4e66\u7684\u8303\u56f4\u3002"),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"Not only can parallelizing a stream lead to poor performance, including liveness failures; it can lead to incorrect results and unpredictable behavior")," (safety failures). Safety failures may result from parallelizing a pipeline that uses mappers, filters, and other programmer-supplied function objects that fail to adhere to their specifications. The Stream specification places stringent requirements on these function objects. For example, the accumulator and combiner functions passed to Stream\u2019s reduce operation must be associative, non-interfering, and stateless. If you violate these requirements (some of which are discussed in Item 46) but run your pipeline sequentially, it will likely yield correct results; if you parallelize it, it will likely fail, perhaps catastrophically. Along these lines, it\u2019s worth noting that even if the parallelized Mersenne primes program had run to completion, it would not have printed the primes in the correct (ascending) order. To preserve the order displayed by the sequential version, you\u2019d have to replace the forEach terminal operation with forEachOrdered, which is guaranteed to traverse parallel streams in encounter order."),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"\u5e76\u884c\u5316\u6d41\u4e0d\u4ec5\u4f1a\u5bfc\u81f4\u7cdf\u7cd5\u7684\u6027\u80fd\uff0c\u5305\u62ec\u6d3b\u52a8\u5931\u8d25\uff1b\u5b83\u4f1a\u5bfc\u81f4\u4e0d\u6b63\u786e\u7684\u7ed3\u679c\u548c\u4e0d\u53ef\u9884\u77e5\u7684\u884c\u4e3a\uff08\u5b89\u5168\u6545\u969c\uff09\u3002")," \u5982\u679c\u7ba1\u9053\u4f7f\u7528\u6620\u5c04\u5668\u3001\u8fc7\u6ee4\u5668\u548c\u5176\u4ed6\u7a0b\u5e8f\u5458\u63d0\u4f9b\u7684\u51fd\u6570\u5bf9\u8c61\uff0c\u800c\u8fd9\u4e9b\u5bf9\u8c61\u6ca1\u6709\u9075\u5b88\u5176\u89c4\u8303\uff0c\u5219\u5e76\u884c\u5316\u7ba1\u9053\u53ef\u80fd\u5bfc\u81f4\u5b89\u5168\u6545\u969c\u3002\u6d41\u89c4\u8303\u5bf9\u8fd9\u4e9b\u529f\u80fd\u5bf9\u8c61\u63d0\u51fa\u4e86\u4e25\u683c\u7684\u8981\u6c42\u3002\u4f8b\u5982\uff0c\u4f20\u9012\u7ed9\u6d41\u7684 reduce \u64cd\u4f5c\u7684\u7d2f\u52a0\u5668\u548c\u7ec4\u5408\u5668\u51fd\u6570\u5fc5\u987b\u662f\u5173\u8054\u7684\u3001\u4e0d\u5e72\u6270\u7684\u548c\u65e0\u72b6\u6001\u7684\u3002\u5982\u679c\u4f60\u8fdd\u53cd\u4e86\u8fd9\u4e9b\u8981\u6c42\uff08\u5176\u4e2d\u4e00\u4e9b\u8981\u6c42\u5728 ",(0,n.kt)("a",{parentName:"p",href:"./Chapter-7-Item-46-Prefer-side-effect-free-functions-in-streams"},"Item-46")," \u4e2d\u8ba8\u8bba\uff09\uff0c\u4f46\u662f\u6309\u987a\u5e8f\u8fd0\u884c\u7ba1\u9053\uff0c\u5219\u53ef\u80fd\u4f1a\u4ea7\u751f\u6b63\u786e\u7684\u7ed3\u679c\uff1b\u5982\u679c\u4f60\u5e76\u884c\u5316\u5b83\uff0c\u5b83\u5f88\u53ef\u80fd\u4f1a\u5931\u8d25\uff0c\u53ef\u80fd\u662f\u707e\u96be\u6027\u7684\u3002\u6cbf\u7740\u8fd9\u4e9b\u601d\u8def\uff0c\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5373\u4f7f\u5e76\u884c\u5316\u7684 Mersenne \u7d20\u6570\u7a0b\u5e8f\u8fd0\u884c\u5230\u5b8c\u6210\uff0c\u5b83\u4e5f\u4e0d\u4f1a\u4ee5\u6b63\u786e\u7684\uff08\u5347\u5e8f\uff09\u987a\u5e8f\u6253\u5370\u7d20\u6570\u3002\u4e3a\u4e86\u4fdd\u7559\u5e8f\u5217\u7248\u672c\u6240\u663e\u793a\u7684\u987a\u5e8f\uff0c\u4f60\u5fc5\u987b\u5c06 forEach \u8fd9\u4e00 Terminal \u64cd\u4f5c\u66ff\u6362\u4e3a forEachOrdered\uff0c\u5b83\u4fdd\u8bc1\u6309\u987a\u5e8f\u904d\u5386\u5e76\u884c\u6d41\u3002"),(0,n.kt)("p",null,"Even assuming that you\u2019re using an efficiently splittable source stream, a parallelizable or cheap terminal operation, and non-interfering function objects, you won\u2019t get a good speedup from parallelization unless the pipeline is doing enough real work to offset the costs associated with parallelism. As a very rough estimate, the number of elements in the stream times the number of lines of code executed per element should be at least a hundred thousand ","[Lea14]","."),(0,n.kt)("p",null,"\u5373\u4f7f\u5047\u8bbe\u4f60\u6b63\u5728\u4f7f\u7528\u4e00\u4e2a\u9ad8\u6548\u7684\u53ef\u5206\u5272\u6e90\u6d41\u3001\u4e00\u4e2a\u53ef\u5e76\u884c\u5316\u7684\u6216\u5ec9\u4ef7\u7684 Terminal \u64cd\u4f5c\uff0c\u4ee5\u53ca\u4e0d\u53d7\u5e72\u6270\u7684\u51fd\u6570\u5bf9\u8c61\uff0c\u4f60\u4e5f\u4e0d\u4f1a\u4ece\u5e76\u884c\u5316\u4e2d\u83b7\u5f97\u826f\u597d\u7684\u52a0\u901f\uff0c\u9664\u975e\u7ba1\u9053\u6b63\u5728\u505a\u8db3\u591f\u7684\u5b9e\u9645\u5de5\u4f5c\u6765\u62b5\u6d88\u4e0e\u5e76\u884c\u6027\u76f8\u5173\u7684\u6210\u672c\u3002\u4f5c\u4e3a\u4e00\u4e2a\u975e\u5e38\u7c97\u7565\u7684\u4f30\u8ba1\uff0c\u6d41\u4e2d\u7684\u5143\u7d20\u6570\u91cf\u4e58\u4ee5\u6bcf\u4e2a\u5143\u7d20\u6267\u884c\u7684\u4ee3\u7801\u884c\u6570\u81f3\u5c11\u5e94\u8be5\u662f 100000 ","[Lea14]","\u3002"),(0,n.kt)("p",null,"It\u2019s important to remember that parallelizing a stream is strictly a performance optimization. As is the case for any optimization, you must test the performance before and after the change to ensure that it is worth doing (Item 67). Ideally, you should perform the test in a realistic system setting. Normally, all parallel stream pipelines in a program run in a common fork-join pool. A single misbehaving pipeline can harm the performance of others in unrelated parts of the system."),(0,n.kt)("p",null,"\u91cd\u8981\u7684\u662f\u8981\u8bb0\u4f4f\uff0c\u5e76\u884c\u5316\u6d41\u4e25\u683c\u6765\u8bf4\u662f\u4e00\u79cd\u6027\u80fd\u4f18\u5316\u3002\u4e0e\u4efb\u4f55\u4f18\u5316\u4e00\u6837\uff0c\u4f60\u5fc5\u987b\u5728\u66f4\u6539\u4e4b\u524d\u548c\u4e4b\u540e\u6d4b\u8bd5\u6027\u80fd\uff0c\u4ee5\u786e\u4fdd\u5b83\u503c\u5f97\u8fdb\u884c\uff08",(0,n.kt)("a",{parentName:"p",href:"./Chapter-9-Item-67-Optimize-judiciously"},"Item-67"),"\uff09\u3002\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u4f60\u5e94\u8be5\u5728\u5b9e\u9645\u7684\u7cfb\u7edf\u8bbe\u7f6e\u4e2d\u6267\u884c\u6d4b\u8bd5\u3002\u901a\u5e38\uff0c\u7a0b\u5e8f\u4e2d\u7684\u6240\u6709\u5e76\u884c\u6d41\u7ba1\u9053\u90fd\u5728\u516c\u5171 fork-join \u6c60\u4e2d\u8fd0\u884c\u3002\u4e00\u4e2a\u884c\u4e3a\u4e0d\u5f53\u7684\u7ba1\u9053\u53ef\u80fd\u4f1a\u635f\u5bb3\u7cfb\u7edf\u4e2d\u4e0d\u76f8\u5173\u90e8\u5206\u7684\u5176\u4ed6\u7ba1\u9053\u7684\u6027\u80fd\u3002"),(0,n.kt)("p",null,"If it sounds like the odds are stacked against you when parallelizing stream pipelines, it\u2019s because they are. An acquaintance who maintains a multimillionline codebase that makes heavy use of streams found only a handful of places where parallel streams were effective. This does not mean that you should refrain from parallelizing streams. Under the right circumstances, it is possible to achieve near-linear speedup in the number of processor cores simply by adding a parallel call to a stream pipeline. Certain domains, such as machine learning and data processing, are particularly amenable to these speedups."),(0,n.kt)("p",null,"\u5982\u679c\u5728\u5e76\u884c\u5316\u6d41\u7ba1\u9053\u65f6\uff0c\u542c\u8d77\u6765\u4f60\u7684\u80dc\u7b97\u975e\u5e38\u5927\uff0c\u90a3\u662f\u56e0\u4e3a\u5b83\u4eec\u786e\u5b9e\u5982\u6b64\u3002\u4e00\u4f4d\u719f\u6089\u7684\u4eba\u7ef4\u62a4\u7740\u5927\u91cf\u4f7f\u7528\u6d41\u7684\u6570\u767e\u4e07\u5728\u7ebf\u4ee3\u7801\u5e93\uff0c\u4ed6\u53d1\u73b0\u53ea\u6709\u5c11\u6570\u51e0\u4e2a\u5730\u65b9\u5e76\u884c\u6d41\u662f\u6709\u6548\u7684\u3002\u8fd9\u5e76\u4e0d\u610f\u5473\u7740\u4f60\u5e94\u8be5\u907f\u514d\u5e76\u884c\u5316\u6d41\u3002\u5728\u9002\u5f53\u7684\u60c5\u51b5\u4e0b\uff0c\u53ef\u4ee5\u901a\u8fc7\u5411\u6d41\u7ba1\u9053\u6dfb\u52a0\u5e76\u884c\u8c03\u7528\u6765\u5b9e\u73b0\u5904\u7406\u5668\u5185\u6838\u6570\u91cf\u7684\u8fd1\u4e4e\u7ebf\u6027\u7684\u52a0\u901f\u3002\u67d0\u4e9b\u9886\u57df\uff0c\u5982\u673a\u5668\u5b66\u4e60\u548c\u6570\u636e\u5904\u7406\uff0c\u7279\u522b\u9002\u5408\u4e8e\u8fd9\u4e9b\u52a0\u901f\u3002"),(0,n.kt)("p",null,"As a simple example of a stream pipeline where parallelism is effective, consider this function for computing \u03c0(n), the number of primes less than or equal to n:"),(0,n.kt)("p",null,"\u4f5c\u4e3a\u4e00\u4e2a\u7b80\u5355\u7684\u4f8b\u5b50\uff0c\u4e00\u4e2a\u6d41\u7ba1\u9053\u5e76\u884c\u6027\u662f\u6709\u6548\u7684\uff0c\u8003\u8651\u8fd9\u4e2a\u51fd\u6570\u8ba1\u7b97 ",(0,n.kt)("inlineCode",{parentName:"p"},"\u03c0(n)"),"\uff0c\u8d28\u6570\u6570\u76ee\u5c0f\u4e8e\u6216\u7b49\u4e8e n\uff1a"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"// Prime-counting stream pipeline - benefits from parallelization\nstatic long pi(long n) {\n    return LongStream.rangeClosed(2, n)\n    .mapToObj(BigInteger::valueOf)\n    .filter(i -> i.isProbablePrime(50))\n    .count();\n}\n")),(0,n.kt)("p",null,"On my machine, it takes 31 seconds to compute \u03c0(108) using this function. Simply adding a parallel() call reduces the time to 9.2 seconds:"),(0,n.kt)("p",null,"\u5728\u6211\u7684\u673a\u5668\u4e0a\uff0c\u9700\u8981 31 \u79d2\u8ba1\u7b97 ",(0,n.kt)("inlineCode",{parentName:"p"},"\u03c0(108)")," \u4f7f\u7528\u8fd9\u4e2a\u51fd\u6570\u3002\u7b80\u5355\u5730\u6dfb\u52a0 ",(0,n.kt)("inlineCode",{parentName:"p"},"parallel()")," \u8c03\u7528\u5c06\u65f6\u95f4\u7f29\u77ed\u5230 9.2 \u79d2\uff1a"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"// Prime-counting stream pipeline - parallel version\nstatic long pi(long n) {\n    return LongStream.rangeClosed(2, n)\n    .parallel()\n    .mapToObj(BigInteger::valueOf)\n    .filter(i -> i.isProbablePrime(50))\n    .count();\n}\n")),(0,n.kt)("p",null,"In other words, parallelizing the computation speeds it up by a factor of 3.7 on my quad-core machine. It\u2019s worth noting that this is not how you\u2019d compute \u03c0(n) for large values of n in practice. There are far more efficient algorithms, notably Lehmer\u2019s formula."),(0,n.kt)("p",null,"\u6362\u53e5\u8bdd\u8bf4\uff0c\u5728\u6211\u7684\u56db\u6838\u8ba1\u7b97\u673a\u4e0a\uff0c\u5e76\u884c\u5316\u7684\u8ba1\u7b97\u901f\u5ea6\u63d0\u9ad8\u4e86 3.7 \u500d\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u8fd9\u4e0d\u662f\u4f60\u5982\u4f55\u8ba1\u7b97 ",(0,n.kt)("inlineCode",{parentName:"p"},"\u03c0(n)")," \u4e3a\u5927 n \u7684\u503c\u3002\u6709\u66f4\u6709\u6548\u7684\u7b97\u6cd5\uff0c\u7279\u522b\u662f Lehmer \u516c\u5f0f\u3002"),(0,n.kt)("p",null,"If you are going to parallelize a stream of random numbers, start with a SplittableRandom instance rather than a ThreadLocalRandom (or the essentially obsolete Random). SplittableRandom is designed for precisely this use, and has the potential for linear speedup. ThreadLocalRandom is designed for use by a single thread, and will adapt itself to function as a parallel stream source, but won\u2019t be as fast as SplittableRandom. Random synchronizes on every operation, so it will result in excessive, parallelism-killing contention."),(0,n.kt)("p",null,"\u5982\u679c\u8981\u5e76\u884c\u5316\u4e00\u4e2a\u968f\u673a\u6570\u6d41\uff0c\u53ef\u4ee5\u4ece\u4e00\u4e2a SplittableRandom \u5b9e\u4f8b\u5f00\u59cb\uff0c\u800c\u4e0d\u662f\u4ece\u4e00\u4e2a ThreadLocalRandom\uff08\u6216\u8005\u672c\u8d28\u4e0a\u5df2\u7ecf\u8fc7\u65f6\u7684 random\uff09\u5f00\u59cb\u3002SplittableRandom \u6b63\u662f\u4e3a\u8fd9\u79cd\u7528\u9014\u800c\u8bbe\u8ba1\u7684\uff0c\u5b83\u5177\u6709\u7ebf\u6027\u52a0\u901f\u7684\u6f5c\u529b\u3002ThreadLocalRandom \u662f\u4e3a\u5355\u4e2a\u7ebf\u7a0b\u8bbe\u8ba1\u7684\uff0c\u5b83\u5c06\u81ea\u9002\u5e94\u4e3a\u5e76\u884c\u6d41\u6e90\uff0c\u4f46\u901f\u5ea6\u6ca1\u6709 SplittableRandom \u5feb\u3002\u968f\u673a\u540c\u6b65\u6bcf\u4e2a\u64cd\u4f5c\uff0c\u56e0\u6b64\u5b83\u5c06\u5bfc\u81f4\u8fc7\u5ea6\u7684\u5e76\u884c\u4e89\u7528\u3002"),(0,n.kt)("p",null,"In summary, do not even attempt to parallelize a stream pipeline unless you have good reason to believe that it will preserve the correctness of the computation and increase its speed. The cost of inappropriately parallelizing a stream can be a program failure or performance disaster. If you believe that parallelism may be justified, ensure that your code remains correct when run in parallel, and do careful performance measurements under realistic conditions. If your code remains correct and these experiments bear out your suspicion of increased performance, then and only then parallelize the stream in production code."),(0,n.kt)("p",null,"\u603b\u4e4b\uff0c\u751a\u81f3\u4e0d\u8981\u5c1d\u8bd5\u5e76\u884c\u5316\u6d41\u7ba1\u9053\uff0c\u9664\u975e\u4f60\u6709\u5145\u5206\u7684\u7406\u7531\u76f8\u4fe1\u5b83\u5c06\u4fdd\u6301\u8ba1\u7b97\u7684\u6b63\u786e\u6027\u4ee5\u53ca\u63d0\u9ad8\u901f\u5ea6\u3002\u4e0d\u9002\u5f53\u5730\u5e76\u884c\u5316\u6d41\u7684\u4ee3\u4ef7\u53ef\u80fd\u662f\u7a0b\u5e8f\u5931\u8d25\u6216\u6027\u80fd\u707e\u96be\u3002\u5982\u679c\u4f60\u8ba4\u4e3a\u5e76\u884c\u6027\u662f\u5408\u7406\u7684\uff0c\u90a3\u4e48\u8bf7\u786e\u4fdd\u4f60\u7684\u4ee3\u7801\u5728\u5e76\u884c\u8fd0\u884c\u65f6\u4fdd\u6301\u6b63\u786e\uff0c\u5e76\u5728\u5b9e\u9645\u60c5\u51b5\u4e0b\u8fdb\u884c\u4ed4\u7ec6\u7684\u6027\u80fd\u5ea6\u91cf\u3002\u5982\u679c\u4f60\u7684\u4ee3\u7801\u4fdd\u6301\u6b63\u786e\uff0c\u5e76\u4e14\u8fd9\u4e9b\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u4f60\u5bf9\u63d0\u9ad8\u6027\u80fd\u7684\u6000\u7591\uff0c\u90a3\u4e48\uff0c\u5e76\u4e14\u53ea\u6709\u8fd9\u6837\uff0c\u624d\u80fd\u5728\u751f\u4ea7\u4ee3\u7801\u4e2d\u5e76\u884c\u5316\u6d41\u3002"),(0,n.kt)("hr",null),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},(0,n.kt)("a",{parentName:"strong",href:"./Chapter-7-Introduction"},"Back to contents of the chapter\uff08\u8fd4\u56de\u7ae0\u8282\u76ee\u5f55\uff09"))),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Previous Item\uff08\u4e0a\u4e00\u6761\u76ee\uff09\uff1a",(0,n.kt)("a",{parentName:"strong",href:"./Chapter-7-Item-47-Prefer-Collection-to-Stream-as-a-return-type"},"Item 47: Prefer Collection to Stream as a return type\uff08\u4f18\u5148\u9009\u62e9 Collection \u800c\u4e0d\u662f\u6d41\u4f5c\u4e3a\u8fd4\u56de\u7c7b\u578b\uff09"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Next Item\uff08\u4e0b\u4e00\u6761\u76ee\uff09\uff1a",(0,n.kt)("a",{parentName:"strong",href:"./Chapter-8-Introduction"},"Chapter 8 Introduction\uff08\u7ae0\u8282\u4ecb\u7ecd\uff09")))))}c.isMDXComponent=!0}}]);